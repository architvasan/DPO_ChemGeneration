2024-05-21 16:36:52,971 INFO    StreamThr :392489 [internal.py:wandb_internal():85] W&B internal server running at pid: 392489, started at: 2024-05-21 16:36:52.969756
2024-05-21 16:36:52,974 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: status
2024-05-21 16:36:52,975 INFO    WriterThread:392489 [datastore.py:open_for_write():87] open: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/run-r8udg150.wandb
2024-05-21 16:36:52,977 DEBUG   SenderThread:392489 [sender.py:send():378] send: header
2024-05-21 16:36:52,986 DEBUG   SenderThread:392489 [sender.py:send():378] send: run
2024-05-21 16:36:53,165 INFO    SenderThread:392489 [dir_watcher.py:__init__():211] watching files in: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files
2024-05-21 16:36:53,165 INFO    SenderThread:392489 [sender.py:_start_run_threads():1123] run started: r8udg150 with start time 1716334612.970156
2024-05-21 16:36:53,179 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: check_version
2024-05-21 16:36:53,180 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: check_version
2024-05-21 16:36:53,232 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: run_start
2024-05-21 16:36:53,250 DEBUG   HandlerThread:392489 [system_info.py:__init__():26] System info init
2024-05-21 16:36:53,250 DEBUG   HandlerThread:392489 [system_info.py:__init__():41] System info init done
2024-05-21 16:36:53,250 INFO    HandlerThread:392489 [system_monitor.py:start():194] Starting system monitor
2024-05-21 16:36:53,251 INFO    SystemMonitor:392489 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-05-21 16:36:53,251 INFO    HandlerThread:392489 [system_monitor.py:probe():214] Collecting system info
2024-05-21 16:36:53,251 INFO    SystemMonitor:392489 [interfaces.py:start():188] Started cpu monitoring
2024-05-21 16:36:53,252 INFO    SystemMonitor:392489 [interfaces.py:start():188] Started disk monitoring
2024-05-21 16:36:53,252 INFO    SystemMonitor:392489 [interfaces.py:start():188] Started gpu monitoring
2024-05-21 16:36:53,253 INFO    SystemMonitor:392489 [interfaces.py:start():188] Started memory monitoring
2024-05-21 16:36:53,253 INFO    SystemMonitor:392489 [interfaces.py:start():188] Started network monitoring
2024-05-21 16:36:53,306 DEBUG   HandlerThread:392489 [system_info.py:probe():150] Probing system
2024-05-21 16:36:53,307 DEBUG   HandlerThread:392489 [system_info.py:_probe_git():135] Probing git
2024-05-21 16:36:53,323 DEBUG   HandlerThread:392489 [system_info.py:_probe_git():143] Probing git done
2024-05-21 16:36:53,323 DEBUG   HandlerThread:392489 [system_info.py:probe():198] Probing system done
2024-05-21 16:36:53,323 DEBUG   HandlerThread:392489 [system_monitor.py:probe():223] {'os': 'Linux-5.4.0-174-generic-x86_64-with-glibc2.31', 'python': '3.10.14', 'heartbeatAt': '2024-05-21T23:36:53.306802', 'startedAt': '2024-05-21T23:36:52.954608', 'docker': None, 'cuda': None, 'args': ('-d', '/lambda_stor/data/avasan/PharmacoData/data/admet_open_data/admet_labelled_data/P-glycoprotein_substrate/data.csv', '-s', 'SMILES', '-l', 'label', '-t', '0.2', '-E', '100'), 'state': 'running', 'program': '/nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/run_script.py', 'codePathLocal': 'run_script.py', 'codePath': 'ModelTraining/MolFormer_Class/run_script.py', 'git': {'remote': 'https://github.com/architvasan/Pharmacokinetic_Modeling.git', 'commit': 'e249d6d63487dc4f5a0cdf798c7e0d608cacc896'}, 'email': None, 'root': '/nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling', 'host': 'lambda0', 'username': 'avasan', 'executable': '/homes/avasan/miniforge3_new/envs/sst_llama/bin/python', 'cpu_count': 40, 'cpu_count_logical': 80, 'cpu_freq': {'current': 2834.850325, 'min': 1000.0, 'max': 3700.0}, 'cpu_freq_per_core': [{'current': 3123.307, 'min': 1000.0, 'max': 3700.0}, {'current': 3090.1, 'min': 1000.0, 'max': 3700.0}, {'current': 3094.827, 'min': 1000.0, 'max': 3700.0}, {'current': 3100.136, 'min': 1000.0, 'max': 3700.0}, {'current': 2397.441, 'min': 1000.0, 'max': 3700.0}, {'current': 3147.167, 'min': 1000.0, 'max': 3700.0}, {'current': 2230.853, 'min': 1000.0, 'max': 3700.0}, {'current': 2265.119, 'min': 1000.0, 'max': 3700.0}, {'current': 2618.891, 'min': 1000.0, 'max': 3700.0}, {'current': 3040.73, 'min': 1000.0, 'max': 3700.0}, {'current': 3049.289, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.009, 'min': 1000.0, 'max': 3700.0}, {'current': 2232.409, 'min': 1000.0, 'max': 3700.0}, {'current': 3119.171, 'min': 1000.0, 'max': 3700.0}, {'current': 2366.907, 'min': 1000.0, 'max': 3700.0}, {'current': 3080.013, 'min': 1000.0, 'max': 3700.0}, {'current': 2649.982, 'min': 1000.0, 'max': 3700.0}, {'current': 3119.371, 'min': 1000.0, 'max': 3700.0}, {'current': 3119.395, 'min': 1000.0, 'max': 3700.0}, {'current': 2656.99, 'min': 1000.0, 'max': 3700.0}, {'current': 3052.166, 'min': 1000.0, 'max': 3700.0}, {'current': 3099.88, 'min': 1000.0, 'max': 3700.0}, {'current': 2599.991, 'min': 1000.0, 'max': 3700.0}, {'current': 2601.482, 'min': 1000.0, 'max': 3700.0}, {'current': 3039.648, 'min': 1000.0, 'max': 3700.0}, {'current': 2619.828, 'min': 1000.0, 'max': 3700.0}, {'current': 3102.527, 'min': 1000.0, 'max': 3700.0}, {'current': 3097.899, 'min': 1000.0, 'max': 3700.0}, {'current': 2770.512, 'min': 1000.0, 'max': 3700.0}, {'current': 3099.856, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.584, 'min': 1000.0, 'max': 3700.0}, {'current': 2640.359, 'min': 1000.0, 'max': 3700.0}, {'current': 2273.982, 'min': 1000.0, 'max': 3700.0}, {'current': 3100.461, 'min': 1000.0, 'max': 3700.0}, {'current': 2601.518, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.532, 'min': 1000.0, 'max': 3700.0}, {'current': 3100.008, 'min': 1000.0, 'max': 3700.0}, {'current': 2319.046, 'min': 1000.0, 'max': 3700.0}, {'current': 2235.118, 'min': 1000.0, 'max': 3700.0}, {'current': 3025.707, 'min': 1000.0, 'max': 3700.0}, {'current': 3166.942, 'min': 1000.0, 'max': 3700.0}, {'current': 2926.455, 'min': 1000.0, 'max': 3700.0}, {'current': 2983.425, 'min': 1000.0, 'max': 3700.0}, {'current': 3100.013, 'min': 1000.0, 'max': 3700.0}, {'current': 2507.741, 'min': 1000.0, 'max': 3700.0}, {'current': 3113.659, 'min': 1000.0, 'max': 3700.0}, {'current': 2197.116, 'min': 1000.0, 'max': 3700.0}, {'current': 2454.795, 'min': 1000.0, 'max': 3700.0}, {'current': 2596.65, 'min': 1000.0, 'max': 3700.0}, {'current': 3105.611, 'min': 1000.0, 'max': 3700.0}, {'current': 3098.591, 'min': 1000.0, 'max': 3700.0}, {'current': 3121.259, 'min': 1000.0, 'max': 3700.0}, {'current': 2347.395, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.194, 'min': 1000.0, 'max': 3700.0}, {'current': 2351.057, 'min': 1000.0, 'max': 3700.0}, {'current': 3093.267, 'min': 1000.0, 'max': 3700.0}, {'current': 2603.015, 'min': 1000.0, 'max': 3700.0}, {'current': 3103.834, 'min': 1000.0, 'max': 3700.0}, {'current': 3106.215, 'min': 1000.0, 'max': 3700.0}, {'current': 2666.682, 'min': 1000.0, 'max': 3700.0}, {'current': 3091.598, 'min': 1000.0, 'max': 3700.0}, {'current': 3091.905, 'min': 1000.0, 'max': 3700.0}, {'current': 2601.653, 'min': 1000.0, 'max': 3700.0}, {'current': 2600.01, 'min': 1000.0, 'max': 3700.0}, {'current': 3020.223, 'min': 1000.0, 'max': 3700.0}, {'current': 2599.868, 'min': 1000.0, 'max': 3700.0}, {'current': 3102.44, 'min': 1000.0, 'max': 3700.0}, {'current': 3067.761, 'min': 1000.0, 'max': 3700.0}, {'current': 2782.739, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.711, 'min': 1000.0, 'max': 3700.0}, {'current': 3100.002, 'min': 1000.0, 'max': 3700.0}, {'current': 2596.755, 'min': 1000.0, 'max': 3700.0}, {'current': 2284.501, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.717, 'min': 1000.0, 'max': 3700.0}, {'current': 2599.735, 'min': 1000.0, 'max': 3700.0}, {'current': 3099.324, 'min': 1000.0, 'max': 3700.0}, {'current': 3101.015, 'min': 1000.0, 'max': 3700.0}, {'current': 2235.276, 'min': 1000.0, 'max': 3700.0}, {'current': 2202.602, 'min': 1000.0, 'max': 3700.0}, {'current': 3097.345, 'min': 1000.0, 'max': 3700.0}], 'disk': {'/': {'total': 1758.8579597473145, 'used': 661.481559753418}}, 'gpu': 'Tesla V100-SXM2-32GB', 'gpu_count': 8, 'gpu_devices': [{'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}], 'memory': {'total': 503.5380401611328}}
2024-05-21 16:36:53,323 INFO    HandlerThread:392489 [system_monitor.py:probe():224] Finished collecting system info
2024-05-21 16:36:53,323 INFO    HandlerThread:392489 [system_monitor.py:probe():227] Publishing system info
2024-05-21 16:36:53,323 DEBUG   HandlerThread:392489 [system_info.py:_save_conda():207] Saving list of conda packages installed into the current environment
2024-05-21 16:36:54,168 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/conda-environment.yaml
2024-05-21 16:36:58,056 DEBUG   HandlerThread:392489 [system_info.py:_save_conda():222] Saving conda packages done
2024-05-21 16:36:58,061 INFO    HandlerThread:392489 [system_monitor.py:probe():229] Finished publishing system info
2024-05-21 16:36:58,069 DEBUG   SenderThread:392489 [sender.py:send():378] send: files
2024-05-21 16:36:58,069 INFO    SenderThread:392489 [sender.py:_save_file():1389] saving file wandb-metadata.json with policy now
2024-05-21 16:36:58,070 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: status_report
2024-05-21 16:36:58,170 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/conda-environment.yaml
2024-05-21 16:36:58,170 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/wandb-metadata.json
2024-05-21 16:36:58,289 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: python_packages
2024-05-21 16:36:58,289 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: python_packages
2024-05-21 16:36:58,291 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: stop_status
2024-05-21 16:36:58,293 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: stop_status
2024-05-21 16:36:58,351 INFO    wandb-upload_0:392489 [upload_job.py:push():130] Uploaded file /tmp/tmpgpx99tf9wandb/or93lz0x-wandb-metadata.json
2024-05-21 16:36:58,383 DEBUG   SenderThread:392489 [sender.py:send():378] send: telemetry
2024-05-21 16:36:59,170 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/requirements.txt
2024-05-21 16:36:59,171 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log
2024-05-21 16:37:01,172 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log
2024-05-21 16:37:01,568 DEBUG   SenderThread:392489 [sender.py:send():378] send: telemetry
2024-05-21 16:37:02,299 DEBUG   SenderThread:392489 [sender.py:send():378] send: telemetry
2024-05-21 16:37:02,462 DEBUG   SenderThread:392489 [sender.py:send():378] send: exit
2024-05-21 16:37:02,462 INFO    SenderThread:392489 [sender.py:send_exit():585] handling exit code: 1
2024-05-21 16:37:02,463 INFO    SenderThread:392489 [sender.py:send_exit():587] handling runtime: 9
2024-05-21 16:37:02,467 INFO    SenderThread:392489 [sender.py:_save_file():1389] saving file wandb-summary.json with policy end
2024-05-21 16:37:02,467 INFO    SenderThread:392489 [sender.py:send_exit():593] send defer
2024-05-21 16:37:02,468 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:02,468 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 0
2024-05-21 16:37:02,468 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:02,468 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 0
2024-05-21 16:37:02,468 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 1
2024-05-21 16:37:02,469 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:02,469 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 1
2024-05-21 16:37:02,469 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:02,469 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 1
2024-05-21 16:37:02,469 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 2
2024-05-21 16:37:02,469 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:02,469 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 2
2024-05-21 16:37:02,470 INFO    HandlerThread:392489 [system_monitor.py:finish():203] Stopping system monitor
2024-05-21 16:37:02,470 DEBUG   SystemMonitor:392489 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2024-05-21 16:37:02,471 INFO    HandlerThread:392489 [interfaces.py:finish():200] Joined cpu monitor
2024-05-21 16:37:02,471 DEBUG   SystemMonitor:392489 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2024-05-21 16:37:02,471 INFO    HandlerThread:392489 [interfaces.py:finish():200] Joined disk monitor
2024-05-21 16:37:02,471 DEBUG   SystemMonitor:392489 [system_monitor.py:_start():183] Publishing last batch of metrics
2024-05-21 16:37:03,175 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log
2024-05-21 16:37:03,176 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/wandb-summary.json
2024-05-21 16:37:04,989 INFO    HandlerThread:392489 [interfaces.py:finish():200] Joined gpu monitor
2024-05-21 16:37:04,990 INFO    HandlerThread:392489 [interfaces.py:finish():200] Joined memory monitor
2024-05-21 16:37:04,991 INFO    HandlerThread:392489 [interfaces.py:finish():200] Joined network monitor
2024-05-21 16:37:04,991 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-21 16:37:04,992 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: status_report
2024-05-21 16:37:04,992 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:04,993 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 2
2024-05-21 16:37:04,993 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 3
2024-05-21 16:37:04,993 DEBUG   SenderThread:392489 [sender.py:send():378] send: stats
2024-05-21 16:37:04,993 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:04,994 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: poll_exit
2024-05-21 16:37:04,994 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 3
2024-05-21 16:37:04,995 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:04,995 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 3
2024-05-21 16:37:04,995 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 4
2024-05-21 16:37:04,996 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:04,996 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 4
2024-05-21 16:37:04,996 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:04,996 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 4
2024-05-21 16:37:04,996 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 5
2024-05-21 16:37:04,996 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:04,996 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 5
2024-05-21 16:37:04,997 DEBUG   SenderThread:392489 [sender.py:send():378] send: summary
2024-05-21 16:37:05,000 INFO    SenderThread:392489 [sender.py:_save_file():1389] saving file wandb-summary.json with policy end
2024-05-21 16:37:05,001 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:05,002 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 5
2024-05-21 16:37:05,002 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 6
2024-05-21 16:37:05,002 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:05,002 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 6
2024-05-21 16:37:05,002 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:05,002 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 6
2024-05-21 16:37:05,008 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: status_report
2024-05-21 16:37:05,081 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 7
2024-05-21 16:37:05,081 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:05,081 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 7
2024-05-21 16:37:05,082 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:05,082 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 7
2024-05-21 16:37:05,179 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/config.yaml
2024-05-21 16:37:05,179 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log
2024-05-21 16:37:05,180 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/wandb-summary.json
2024-05-21 16:37:05,464 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-21 16:37:08,214 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 8
2024-05-21 16:37:08,214 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: poll_exit
2024-05-21 16:37:08,214 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:08,215 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 8
2024-05-21 16:37:08,215 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:08,215 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 8
2024-05-21 16:37:08,215 INFO    SenderThread:392489 [job_builder.py:build():432] Attempting to build job artifact
2024-05-21 16:37:08,217 INFO    SenderThread:392489 [job_builder.py:_get_source_type():565] is repo sourced job
2024-05-21 16:37:08,247 INFO    SenderThread:392489 [job_builder.py:build():541] adding wandb-job metadata file
2024-05-21 16:37:08,254 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 9
2024-05-21 16:37:08,255 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:08,255 DEBUG   SenderThread:392489 [sender.py:send():378] send: artifact
2024-05-21 16:37:08,255 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 9
2024-05-21 16:37:08,466 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-21 16:37:08,720 INFO    wandb-upload_1:392489 [upload_job.py:push():88] Uploaded file /tmp/tmpxv73y1dm/wandb-job.json
2024-05-21 16:37:08,722 INFO    wandb-upload_0:392489 [upload_job.py:push():88] Uploaded file /homes/avasan/.local/share/wandb/artifacts/staging/tmpy84v91fk
2024-05-21 16:37:09,182 INFO    Thread-12 :392489 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log
2024-05-21 16:37:09,214 INFO    SenderThread:392489 [sender.py:send_artifact():1467] sent artifact job-https___github.com_architvasan_Pharmacokinetic_Modeling.git_ModelTraining_MolFormer_Class_run_script.py - {'id': 'QXJ0aWZhY3Q6ODQ1Mzk0Mzcw', 'state': 'PENDING', 'artifactSequence': {'id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NzczNjczMg==', 'latestArtifact': None}}
2024-05-21 16:37:09,215 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:09,215 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 9
2024-05-21 16:37:09,215 INFO    SenderThread:392489 [dir_watcher.py:finish():358] shutting down directory watcher
2024-05-21 16:37:10,183 INFO    SenderThread:392489 [dir_watcher.py:finish():388] scan: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files
2024-05-21 16:37:10,184 INFO    SenderThread:392489 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/config.yaml config.yaml
2024-05-21 16:37:10,184 INFO    SenderThread:392489 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/conda-environment.yaml conda-environment.yaml
2024-05-21 16:37:10,187 INFO    SenderThread:392489 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/wandb-metadata.json wandb-metadata.json
2024-05-21 16:37:10,187 INFO    SenderThread:392489 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/requirements.txt requirements.txt
2024-05-21 16:37:10,189 INFO    SenderThread:392489 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log output.log
2024-05-21 16:37:10,193 INFO    SenderThread:392489 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/wandb-summary.json wandb-summary.json
2024-05-21 16:37:10,195 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 10
2024-05-21 16:37:10,195 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: poll_exit
2024-05-21 16:37:10,195 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:10,198 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 10
2024-05-21 16:37:10,198 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:10,199 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 10
2024-05-21 16:37:10,199 INFO    SenderThread:392489 [file_pusher.py:finish():169] shutting down file pusher
2024-05-21 16:37:10,366 INFO    wandb-upload_1:392489 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/config.yaml
2024-05-21 16:37:10,399 INFO    wandb-upload_4:392489 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/wandb-summary.json
2024-05-21 16:37:10,442 INFO    wandb-upload_0:392489 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/conda-environment.yaml
2024-05-21 16:37:10,442 INFO    wandb-upload_2:392489 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/requirements.txt
2024-05-21 16:37:10,467 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-21 16:37:10,468 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: poll_exit
2024-05-21 16:37:10,485 INFO    wandb-upload_3:392489 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/files/output.log
2024-05-21 16:37:10,686 INFO    Thread-11 (_thread_body):392489 [sender.py:transition_state():613] send defer: 11
2024-05-21 16:37:10,686 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:10,687 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 11
2024-05-21 16:37:10,687 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:10,687 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 11
2024-05-21 16:37:10,687 INFO    SenderThread:392489 [file_pusher.py:join():175] waiting for file pusher
2024-05-21 16:37:10,688 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 12
2024-05-21 16:37:10,688 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:10,688 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 12
2024-05-21 16:37:10,688 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:10,688 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 12
2024-05-21 16:37:10,688 INFO    SenderThread:392489 [file_stream.py:finish():601] file stream finish called
2024-05-21 16:37:10,727 INFO    SenderThread:392489 [file_stream.py:finish():605] file stream finish is done
2024-05-21 16:37:10,727 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 13
2024-05-21 16:37:10,727 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:10,727 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 13
2024-05-21 16:37:10,728 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:10,728 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 13
2024-05-21 16:37:10,728 INFO    SenderThread:392489 [sender.py:transition_state():613] send defer: 14
2024-05-21 16:37:10,728 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: defer
2024-05-21 16:37:10,728 DEBUG   SenderThread:392489 [sender.py:send():378] send: final
2024-05-21 16:37:10,728 INFO    HandlerThread:392489 [handler.py:handle_request_defer():184] handle defer: 14
2024-05-21 16:37:10,728 DEBUG   SenderThread:392489 [sender.py:send():378] send: footer
2024-05-21 16:37:10,729 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: defer
2024-05-21 16:37:10,729 INFO    SenderThread:392489 [sender.py:send_request_defer():609] handle sender defer: 14
2024-05-21 16:37:10,729 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-21 16:37:10,730 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: poll_exit
2024-05-21 16:37:10,730 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-21 16:37:10,730 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: poll_exit
2024-05-21 16:37:10,731 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: server_info
2024-05-21 16:37:10,731 DEBUG   SenderThread:392489 [sender.py:send_request():405] send_request: server_info
2024-05-21 16:37:10,734 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: get_summary
2024-05-21 16:37:10,735 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: sampled_history
2024-05-21 16:37:10,735 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: internal_messages
2024-05-21 16:37:10,772 INFO    MainThread:392489 [wandb_run.py:_footer_history_summary_info():3994] rendering history
2024-05-21 16:37:10,772 INFO    MainThread:392489 [wandb_run.py:_footer_history_summary_info():4026] rendering summary
2024-05-21 16:37:10,773 INFO    MainThread:392489 [wandb_run.py:_footer_sync_info():3953] logging synced files
2024-05-21 16:37:10,773 DEBUG   HandlerThread:392489 [handler.py:handle_request():158] handle_request: shutdown
2024-05-21 16:37:10,773 INFO    HandlerThread:392489 [handler.py:finish():882] shutting down handler
2024-05-21 16:37:11,731 INFO    WriterThread:392489 [datastore.py:close():296] close: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/wandb/run-20240521_163652-r8udg150/run-r8udg150.wandb
2024-05-21 16:37:11,772 INFO    SenderThread:392489 [sender.py:finish():1545] shutting down sender
2024-05-21 16:37:11,772 INFO    SenderThread:392489 [file_pusher.py:finish():169] shutting down file pusher
2024-05-21 16:37:11,773 INFO    SenderThread:392489 [file_pusher.py:join():175] waiting for file pusher
