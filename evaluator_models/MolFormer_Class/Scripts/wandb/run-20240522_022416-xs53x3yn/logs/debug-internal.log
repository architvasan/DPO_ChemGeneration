2024-05-22 02:24:16,124 INFO    StreamThr :1229679 [internal.py:wandb_internal():85] W&B internal server running at pid: 1229679, started at: 2024-05-22 02:24:16.123092
2024-05-22 02:24:16,127 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: status
2024-05-22 02:24:16,130 INFO    WriterThread:1229679 [datastore.py:open_for_write():87] open: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/run-xs53x3yn.wandb
2024-05-22 02:24:16,131 DEBUG   SenderThread:1229679 [sender.py:send():378] send: header
2024-05-22 02:24:16,141 DEBUG   SenderThread:1229679 [sender.py:send():378] send: run
2024-05-22 02:24:16,343 INFO    SenderThread:1229679 [dir_watcher.py:__init__():211] watching files in: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files
2024-05-22 02:24:16,344 INFO    SenderThread:1229679 [sender.py:_start_run_threads():1123] run started: xs53x3yn with start time 1716369856.124058
2024-05-22 02:24:16,354 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: check_version
2024-05-22 02:24:16,354 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: check_version
2024-05-22 02:24:16,408 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: run_start
2024-05-22 02:24:16,443 DEBUG   HandlerThread:1229679 [system_info.py:__init__():26] System info init
2024-05-22 02:24:16,444 DEBUG   HandlerThread:1229679 [system_info.py:__init__():41] System info init done
2024-05-22 02:24:16,444 INFO    HandlerThread:1229679 [system_monitor.py:start():194] Starting system monitor
2024-05-22 02:24:16,444 INFO    SystemMonitor:1229679 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-05-22 02:24:16,444 INFO    HandlerThread:1229679 [system_monitor.py:probe():214] Collecting system info
2024-05-22 02:24:16,444 INFO    SystemMonitor:1229679 [interfaces.py:start():188] Started cpu monitoring
2024-05-22 02:24:16,445 INFO    SystemMonitor:1229679 [interfaces.py:start():188] Started disk monitoring
2024-05-22 02:24:16,446 INFO    SystemMonitor:1229679 [interfaces.py:start():188] Started gpu monitoring
2024-05-22 02:24:16,446 INFO    SystemMonitor:1229679 [interfaces.py:start():188] Started memory monitoring
2024-05-22 02:24:16,446 INFO    SystemMonitor:1229679 [interfaces.py:start():188] Started network monitoring
2024-05-22 02:24:16,493 DEBUG   HandlerThread:1229679 [system_info.py:probe():150] Probing system
2024-05-22 02:24:16,495 DEBUG   HandlerThread:1229679 [system_info.py:_probe_git():135] Probing git
2024-05-22 02:24:16,511 DEBUG   HandlerThread:1229679 [system_info.py:_probe_git():143] Probing git done
2024-05-22 02:24:16,511 DEBUG   HandlerThread:1229679 [system_info.py:probe():198] Probing system done
2024-05-22 02:24:16,512 DEBUG   HandlerThread:1229679 [system_monitor.py:probe():223] {'os': 'Linux-5.4.0-174-generic-x86_64-with-glibc2.31', 'python': '3.10.14', 'heartbeatAt': '2024-05-22T09:24:16.493859', 'startedAt': '2024-05-22T09:24:16.108211', 'docker': None, 'cuda': None, 'args': ('-d', '/lambda_stor/data/avasan/PharmacoData/data/admet_open_data/admet_labelled_data/Scripts//data.csv', '-s', 'SMILES', '-l', 'label', '-t', '0.2', '-E', '100'), 'state': 'running', 'program': '/nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/run_script.py', 'codePathLocal': 'run_script.py', 'codePath': 'ModelTraining/MolFormer_Class/Scripts/run_script.py', 'git': {'remote': 'https://github.com/architvasan/Pharmacokinetic_Modeling.git', 'commit': 'e249d6d63487dc4f5a0cdf798c7e0d608cacc896'}, 'email': None, 'root': '/nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling', 'host': 'lambda0', 'username': 'avasan', 'executable': '/homes/avasan/miniforge3_new/envs/sst_llama/bin/python', 'cpu_count': 40, 'cpu_count_logical': 80, 'cpu_freq': {'current': 2823.364775000001, 'min': 1000.0, 'max': 3700.0}, 'cpu_freq_per_core': [{'current': 3095.039, 'min': 1000.0, 'max': 3700.0}, {'current': 3049.462, 'min': 1000.0, 'max': 3700.0}, {'current': 2984.367, 'min': 1000.0, 'max': 3700.0}, {'current': 3100.019, 'min': 1000.0, 'max': 3700.0}, {'current': 2216.477, 'min': 1000.0, 'max': 3700.0}, {'current': 3132.941, 'min': 1000.0, 'max': 3700.0}, {'current': 3134.079, 'min': 1000.0, 'max': 3700.0}, {'current': 3187.154, 'min': 1000.0, 'max': 3700.0}, {'current': 2543.69, 'min': 1000.0, 'max': 3700.0}, {'current': 2530.055, 'min': 1000.0, 'max': 3700.0}, {'current': 2575.356, 'min': 1000.0, 'max': 3700.0}, {'current': 3186.957, 'min': 1000.0, 'max': 3700.0}, {'current': 2266.437, 'min': 1000.0, 'max': 3700.0}, {'current': 3187.379, 'min': 1000.0, 'max': 3700.0}, {'current': 3186.391, 'min': 1000.0, 'max': 3700.0}, {'current': 2529.173, 'min': 1000.0, 'max': 3700.0}, {'current': 2703.805, 'min': 1000.0, 'max': 3700.0}, {'current': 2941.862, 'min': 1000.0, 'max': 3700.0}, {'current': 2703.445, 'min': 1000.0, 'max': 3700.0}, {'current': 3184.557, 'min': 1000.0, 'max': 3700.0}, {'current': 2632.23, 'min': 1000.0, 'max': 3700.0}, {'current': 2562.286, 'min': 1000.0, 'max': 3700.0}, {'current': 2723.867, 'min': 1000.0, 'max': 3700.0}, {'current': 3098.423, 'min': 1000.0, 'max': 3700.0}, {'current': 2580.451, 'min': 1000.0, 'max': 3700.0}, {'current': 2199.802, 'min': 1000.0, 'max': 3700.0}, {'current': 2425.543, 'min': 1000.0, 'max': 3700.0}, {'current': 2725.42, 'min': 1000.0, 'max': 3700.0}, {'current': 2302.907, 'min': 1000.0, 'max': 3700.0}, {'current': 2274.419, 'min': 1000.0, 'max': 3700.0}, {'current': 2703.681, 'min': 1000.0, 'max': 3700.0}, {'current': 3132.555, 'min': 1000.0, 'max': 3700.0}, {'current': 2783.653, 'min': 1000.0, 'max': 3700.0}, {'current': 2861.03, 'min': 1000.0, 'max': 3700.0}, {'current': 3151.896, 'min': 1000.0, 'max': 3700.0}, {'current': 2721.936, 'min': 1000.0, 'max': 3700.0}, {'current': 3098.682, 'min': 1000.0, 'max': 3700.0}, {'current': 2729.69, 'min': 1000.0, 'max': 3700.0}, {'current': 3228.675, 'min': 1000.0, 'max': 3700.0}, {'current': 2633.182, 'min': 1000.0, 'max': 3700.0}, {'current': 3057.247, 'min': 1000.0, 'max': 3700.0}, {'current': 2996.441, 'min': 1000.0, 'max': 3700.0}, {'current': 2830.726, 'min': 1000.0, 'max': 3700.0}, {'current': 3190.126, 'min': 1000.0, 'max': 3700.0}, {'current': 2290.754, 'min': 1000.0, 'max': 3700.0}, {'current': 3102.04, 'min': 1000.0, 'max': 3700.0}, {'current': 3066.436, 'min': 1000.0, 'max': 3700.0}, {'current': 3098.987, 'min': 1000.0, 'max': 3700.0}, {'current': 2777.795, 'min': 1000.0, 'max': 3700.0}, {'current': 2253.306, 'min': 1000.0, 'max': 3700.0}, {'current': 2669.689, 'min': 1000.0, 'max': 3700.0}, {'current': 3097.198, 'min': 1000.0, 'max': 3700.0}, {'current': 2273.413, 'min': 1000.0, 'max': 3700.0}, {'current': 3258.932, 'min': 1000.0, 'max': 3700.0}, {'current': 3123.33, 'min': 1000.0, 'max': 3700.0}, {'current': 2201.038, 'min': 1000.0, 'max': 3700.0}, {'current': 2595.928, 'min': 1000.0, 'max': 3700.0}, {'current': 2765.567, 'min': 1000.0, 'max': 3700.0}, {'current': 2599.687, 'min': 1000.0, 'max': 3700.0}, {'current': 3244.31, 'min': 1000.0, 'max': 3700.0}, {'current': 3060.61, 'min': 1000.0, 'max': 3700.0}, {'current': 2685.169, 'min': 1000.0, 'max': 3700.0}, {'current': 2602.835, 'min': 1000.0, 'max': 3700.0}, {'current': 3236.74, 'min': 1000.0, 'max': 3700.0}, {'current': 2698.583, 'min': 1000.0, 'max': 3700.0}, {'current': 2533.05, 'min': 1000.0, 'max': 3700.0}, {'current': 2350.88, 'min': 1000.0, 'max': 3700.0}, {'current': 2603.549, 'min': 1000.0, 'max': 3700.0}, {'current': 2201.917, 'min': 1000.0, 'max': 3700.0}, {'current': 2269.946, 'min': 1000.0, 'max': 3700.0}, {'current': 2599.879, 'min': 1000.0, 'max': 3700.0}, {'current': 3194.799, 'min': 1000.0, 'max': 3700.0}, {'current': 3073.066, 'min': 1000.0, 'max': 3700.0}, {'current': 2959.547, 'min': 1000.0, 'max': 3700.0}, {'current': 3237.977, 'min': 1000.0, 'max': 3700.0}, {'current': 2600.059, 'min': 1000.0, 'max': 3700.0}, {'current': 3162.665, 'min': 1000.0, 'max': 3700.0}, {'current': 2598.37, 'min': 1000.0, 'max': 3700.0}, {'current': 3277.525, 'min': 1000.0, 'max': 3700.0}, {'current': 2406.6, 'min': 1000.0, 'max': 3700.0}], 'disk': {'/': {'total': 1758.8579597473145, 'used': 661.9618263244629}}, 'gpu': 'Tesla V100-SXM2-32GB', 'gpu_count': 8, 'gpu_devices': [{'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}], 'memory': {'total': 503.5380401611328}}
2024-05-22 02:24:16,512 INFO    HandlerThread:1229679 [system_monitor.py:probe():224] Finished collecting system info
2024-05-22 02:24:16,512 INFO    HandlerThread:1229679 [system_monitor.py:probe():227] Publishing system info
2024-05-22 02:24:16,512 DEBUG   HandlerThread:1229679 [system_info.py:_save_conda():207] Saving list of conda packages installed into the current environment
2024-05-22 02:24:17,346 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/conda-environment.yaml
2024-05-22 02:24:22,097 DEBUG   HandlerThread:1229679 [system_info.py:_save_conda():222] Saving conda packages done
2024-05-22 02:24:22,101 INFO    HandlerThread:1229679 [system_monitor.py:probe():229] Finished publishing system info
2024-05-22 02:24:22,120 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: status_report
2024-05-22 02:24:22,121 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: keepalive
2024-05-22 02:24:22,121 DEBUG   SenderThread:1229679 [sender.py:send():378] send: files
2024-05-22 02:24:22,121 INFO    SenderThread:1229679 [sender.py:_save_file():1389] saving file wandb-metadata.json with policy now
2024-05-22 02:24:22,348 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/conda-environment.yaml
2024-05-22 02:24:22,349 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/wandb-metadata.json
2024-05-22 02:24:22,351 INFO    wandb-upload_0:1229679 [upload_job.py:push():130] Uploaded file /tmp/tmpyp1sko7nwandb/noz15eyv-wandb-metadata.json
2024-05-22 02:24:22,395 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: python_packages
2024-05-22 02:24:22,395 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: python_packages
2024-05-22 02:24:22,396 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: stop_status
2024-05-22 02:24:22,399 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: stop_status
2024-05-22 02:24:22,531 DEBUG   SenderThread:1229679 [sender.py:send():378] send: telemetry
2024-05-22 02:24:23,350 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/requirements.txt
2024-05-22 02:24:23,350 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:25,351 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:25,667 DEBUG   SenderThread:1229679 [sender.py:send():378] send: telemetry
2024-05-22 02:24:26,281 DEBUG   SenderThread:1229679 [sender.py:send():378] send: telemetry
2024-05-22 02:24:26,430 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: status_report
2024-05-22 02:24:26,437 DEBUG   SenderThread:1229679 [sender.py:send():378] send: exit
2024-05-22 02:24:26,438 INFO    SenderThread:1229679 [sender.py:send_exit():585] handling exit code: 1
2024-05-22 02:24:26,438 INFO    SenderThread:1229679 [sender.py:send_exit():587] handling runtime: 10
2024-05-22 02:24:26,441 INFO    SenderThread:1229679 [sender.py:_save_file():1389] saving file wandb-summary.json with policy end
2024-05-22 02:24:26,442 INFO    SenderThread:1229679 [sender.py:send_exit():593] send defer
2024-05-22 02:24:26,442 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:26,442 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 0
2024-05-22 02:24:26,443 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:26,443 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 0
2024-05-22 02:24:26,443 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 1
2024-05-22 02:24:26,443 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:26,443 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 1
2024-05-22 02:24:26,443 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:26,443 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 1
2024-05-22 02:24:26,443 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 2
2024-05-22 02:24:26,443 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:26,443 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 2
2024-05-22 02:24:26,443 INFO    HandlerThread:1229679 [system_monitor.py:finish():203] Stopping system monitor
2024-05-22 02:24:26,444 DEBUG   SystemMonitor:1229679 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2024-05-22 02:24:26,444 INFO    HandlerThread:1229679 [interfaces.py:finish():200] Joined cpu monitor
2024-05-22 02:24:26,444 DEBUG   SystemMonitor:1229679 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2024-05-22 02:24:26,445 INFO    HandlerThread:1229679 [interfaces.py:finish():200] Joined disk monitor
2024-05-22 02:24:26,445 DEBUG   SystemMonitor:1229679 [system_monitor.py:_start():183] Publishing last batch of metrics
2024-05-22 02:24:27,354 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:27,355 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_created():271] file/dir created: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/wandb-summary.json
2024-05-22 02:24:28,357 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:29,065 INFO    HandlerThread:1229679 [interfaces.py:finish():200] Joined gpu monitor
2024-05-22 02:24:29,066 INFO    HandlerThread:1229679 [interfaces.py:finish():200] Joined memory monitor
2024-05-22 02:24:29,066 INFO    HandlerThread:1229679 [interfaces.py:finish():200] Joined network monitor
2024-05-22 02:24:29,066 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-22 02:24:29,068 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:29,068 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 2
2024-05-22 02:24:29,068 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 3
2024-05-22 02:24:29,068 DEBUG   SenderThread:1229679 [sender.py:send():378] send: stats
2024-05-22 02:24:29,069 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: poll_exit
2024-05-22 02:24:29,069 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:29,070 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 3
2024-05-22 02:24:29,070 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:29,070 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 3
2024-05-22 02:24:29,070 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 4
2024-05-22 02:24:29,070 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:29,070 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 4
2024-05-22 02:24:29,071 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:29,071 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 4
2024-05-22 02:24:29,071 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 5
2024-05-22 02:24:29,071 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:29,071 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 5
2024-05-22 02:24:29,072 DEBUG   SenderThread:1229679 [sender.py:send():378] send: summary
2024-05-22 02:24:29,075 INFO    SenderThread:1229679 [sender.py:_save_file():1389] saving file wandb-summary.json with policy end
2024-05-22 02:24:29,076 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:29,076 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 5
2024-05-22 02:24:29,076 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 6
2024-05-22 02:24:29,076 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:29,076 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 6
2024-05-22 02:24:29,076 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:29,076 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 6
2024-05-22 02:24:29,081 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: status_report
2024-05-22 02:24:29,153 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 7
2024-05-22 02:24:29,153 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:29,153 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 7
2024-05-22 02:24:29,154 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:29,154 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 7
2024-05-22 02:24:29,358 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/config.yaml
2024-05-22 02:24:29,359 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/wandb-summary.json
2024-05-22 02:24:29,359 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:29,441 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-22 02:24:32,215 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 8
2024-05-22 02:24:32,215 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: poll_exit
2024-05-22 02:24:32,215 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:32,216 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 8
2024-05-22 02:24:32,216 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:32,216 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 8
2024-05-22 02:24:32,217 INFO    SenderThread:1229679 [job_builder.py:build():432] Attempting to build job artifact
2024-05-22 02:24:32,217 INFO    SenderThread:1229679 [job_builder.py:_get_source_type():565] is repo sourced job
2024-05-22 02:24:32,248 INFO    SenderThread:1229679 [job_builder.py:build():541] adding wandb-job metadata file
2024-05-22 02:24:32,255 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 9
2024-05-22 02:24:32,256 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:32,256 DEBUG   SenderThread:1229679 [sender.py:send():378] send: artifact
2024-05-22 02:24:32,256 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 9
2024-05-22 02:24:32,361 INFO    Thread-12 :1229679 [dir_watcher.py:_on_file_modified():288] file/dir modified: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:32,444 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-22 02:24:32,706 INFO    wandb-upload_1:1229679 [upload_job.py:push():88] Uploaded file /tmp/tmpyjg3hi0z/wandb-job.json
2024-05-22 02:24:32,748 INFO    wandb-upload_0:1229679 [upload_job.py:push():88] Uploaded file /homes/avasan/.local/share/wandb/artifacts/staging/tmpc0c3ew8r
2024-05-22 02:24:33,262 INFO    SenderThread:1229679 [sender.py:send_artifact():1467] sent artifact job-https___github.com_architvasan_Pharmacokinetic_Modeling.git_ModelTraining_MolFormer_Class_Scripts_run_script.py - {'id': 'QXJ0aWZhY3Q6ODQ1OTIwOTI3', 'state': 'PENDING', 'artifactSequence': {'id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjE3NzkzNDk0NQ==', 'latestArtifact': None}}
2024-05-22 02:24:33,262 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:33,262 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 9
2024-05-22 02:24:33,262 INFO    SenderThread:1229679 [dir_watcher.py:finish():358] shutting down directory watcher
2024-05-22 02:24:33,362 INFO    SenderThread:1229679 [dir_watcher.py:finish():388] scan: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files
2024-05-22 02:24:33,363 INFO    SenderThread:1229679 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/config.yaml config.yaml
2024-05-22 02:24:33,363 INFO    SenderThread:1229679 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/conda-environment.yaml conda-environment.yaml
2024-05-22 02:24:33,363 INFO    SenderThread:1229679 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/wandb-metadata.json wandb-metadata.json
2024-05-22 02:24:33,363 INFO    SenderThread:1229679 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/requirements.txt requirements.txt
2024-05-22 02:24:33,366 INFO    SenderThread:1229679 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log output.log
2024-05-22 02:24:33,371 INFO    SenderThread:1229679 [dir_watcher.py:finish():402] scan save: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/wandb-summary.json wandb-summary.json
2024-05-22 02:24:33,374 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 10
2024-05-22 02:24:33,375 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: poll_exit
2024-05-22 02:24:33,375 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:33,378 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 10
2024-05-22 02:24:33,379 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:33,379 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 10
2024-05-22 02:24:33,379 INFO    SenderThread:1229679 [file_pusher.py:finish():169] shutting down file pusher
2024-05-22 02:24:33,445 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-22 02:24:33,446 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: poll_exit
2024-05-22 02:24:33,524 INFO    wandb-upload_1:1229679 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/config.yaml
2024-05-22 02:24:33,555 INFO    wandb-upload_2:1229679 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/requirements.txt
2024-05-22 02:24:33,595 INFO    wandb-upload_0:1229679 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/conda-environment.yaml
2024-05-22 02:24:33,596 INFO    wandb-upload_3:1229679 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/output.log
2024-05-22 02:24:33,599 INFO    wandb-upload_4:1229679 [upload_job.py:push():130] Uploaded file /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/files/wandb-summary.json
2024-05-22 02:24:33,799 INFO    Thread-11 (_thread_body):1229679 [sender.py:transition_state():613] send defer: 11
2024-05-22 02:24:33,800 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:33,800 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 11
2024-05-22 02:24:33,800 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:33,801 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 11
2024-05-22 02:24:33,801 INFO    SenderThread:1229679 [file_pusher.py:join():175] waiting for file pusher
2024-05-22 02:24:33,801 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 12
2024-05-22 02:24:33,801 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:33,801 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 12
2024-05-22 02:24:33,801 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:33,801 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 12
2024-05-22 02:24:33,801 INFO    SenderThread:1229679 [file_stream.py:finish():601] file stream finish called
2024-05-22 02:24:34,263 INFO    SenderThread:1229679 [file_stream.py:finish():605] file stream finish is done
2024-05-22 02:24:34,263 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 13
2024-05-22 02:24:34,263 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:34,263 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 13
2024-05-22 02:24:34,263 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:34,264 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 13
2024-05-22 02:24:34,264 INFO    SenderThread:1229679 [sender.py:transition_state():613] send defer: 14
2024-05-22 02:24:34,264 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: defer
2024-05-22 02:24:34,264 DEBUG   SenderThread:1229679 [sender.py:send():378] send: final
2024-05-22 02:24:34,264 INFO    HandlerThread:1229679 [handler.py:handle_request_defer():184] handle defer: 14
2024-05-22 02:24:34,264 DEBUG   SenderThread:1229679 [sender.py:send():378] send: footer
2024-05-22 02:24:34,265 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: defer
2024-05-22 02:24:34,265 INFO    SenderThread:1229679 [sender.py:send_request_defer():609] handle sender defer: 14
2024-05-22 02:24:34,265 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-22 02:24:34,266 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: poll_exit
2024-05-22 02:24:34,266 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: poll_exit
2024-05-22 02:24:34,267 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: poll_exit
2024-05-22 02:24:34,267 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: server_info
2024-05-22 02:24:34,267 DEBUG   SenderThread:1229679 [sender.py:send_request():405] send_request: server_info
2024-05-22 02:24:34,269 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: get_summary
2024-05-22 02:24:34,270 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: sampled_history
2024-05-22 02:24:34,270 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: internal_messages
2024-05-22 02:24:34,304 INFO    MainThread:1229679 [wandb_run.py:_footer_history_summary_info():3994] rendering history
2024-05-22 02:24:34,304 INFO    MainThread:1229679 [wandb_run.py:_footer_history_summary_info():4026] rendering summary
2024-05-22 02:24:34,304 INFO    MainThread:1229679 [wandb_run.py:_footer_sync_info():3953] logging synced files
2024-05-22 02:24:34,305 DEBUG   HandlerThread:1229679 [handler.py:handle_request():158] handle_request: shutdown
2024-05-22 02:24:34,305 INFO    HandlerThread:1229679 [handler.py:finish():882] shutting down handler
2024-05-22 02:24:35,267 INFO    WriterThread:1229679 [datastore.py:close():296] close: /nfs/lambda_stor_01/data/avasan/Pharmacokinetic_Modeling/ModelTraining/MolFormer_Class/Scripts/wandb/run-20240522_022416-xs53x3yn/run-xs53x3yn.wandb
2024-05-22 02:24:35,304 INFO    SenderThread:1229679 [sender.py:finish():1545] shutting down sender
2024-05-22 02:24:35,304 INFO    SenderThread:1229679 [file_pusher.py:finish():169] shutting down file pusher
2024-05-22 02:24:35,304 INFO    SenderThread:1229679 [file_pusher.py:join():175] waiting for file pusher
